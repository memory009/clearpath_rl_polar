#!/usr/bin/env python3
"""
æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿‡æ‹Ÿåˆåˆ°ç®€å•ä»»åŠ¡
"""

import sys
sys.path.append('.')

from algorithms.td3_polar import TD3Agent
from envs.clearpath_nav_env import ClearpathNavEnv
from utils.config import TD3Config
import numpy as np
import matplotlib.pyplot as plt

print("="*70)
print("è¿‡æ‹Ÿåˆè¯Šæ–­")
print("="*70)

config = TD3Config()
agent = TD3Agent(12, 2, 0.5, config)
agent.load('./models/final_20251009_105845')

# æµ‹è¯•1: åœ¨åŸå§‹ç›®æ ‡ç‚¹ä¸Šæµ‹è¯•ä¸€è‡´æ€§
print("\nã€æµ‹è¯•1ã€‘åœ¨è®­ç»ƒç›®æ ‡(2,2)ä¸Šçš„ä¸€è‡´æ€§")
print("è¿è¡Œ10æ¬¡episodeï¼Œè®°å½•æ­¥æ•°å’Œè½¨è¿¹...")

original_env = ClearpathNavEnv(goal_pos=(2.0, 2.0))
original_steps = []
original_actions = []

for ep in range(10):
    obs, _ = original_env.reset()
    done = False
    step = 0
    actions = []
    
    while not done and step < 256:
        action = agent.select_action(obs)
        obs, reward, done, truncated, info = original_env.step(action)
        actions.append(action.copy())
        step += 1
        
        if done or truncated:
            break
    
    original_steps.append(step)
    original_actions.append(np.array(actions))
    print(f"  Episode {ep+1}: {step}æ­¥ {'âœ“åˆ°è¾¾' if info.get('goal_reached') else 'âœ—è¶…æ—¶'}")

print(f"\næ­¥æ•°ç»Ÿè®¡:")
print(f"  å¹³å‡: {np.mean(original_steps):.1f}æ­¥")
print(f"  æ ‡å‡†å·®: {np.std(original_steps):.2f}æ­¥")
print(f"  èŒƒå›´: [{min(original_steps)}, {max(original_steps)}]")

if np.std(original_steps) < 3:
    print(f"  âš ï¸  æ ‡å‡†å·®å¾ˆå° - ç½‘ç»œè¾“å‡ºé«˜åº¦ä¸€è‡´ï¼ˆå¯èƒ½è¿‡æ‹Ÿåˆï¼‰")

# è®¡ç®—åŠ¨ä½œçš„ä¸€è‡´æ€§
print(f"\nåŠ¨ä½œä¸€è‡´æ€§åˆ†æ:")
min_len = min(len(a) for a in original_actions)
trimmed_actions = [a[:min_len] for a in original_actions]
actions_array = np.array(trimmed_actions)  # shape: (10, min_len, 2)

linear_std = np.mean(np.std(actions_array[:, :, 0], axis=0))
angular_std = np.mean(np.std(actions_array[:, :, 1], axis=0))

print(f"  çº¿é€Ÿåº¦æ ‡å‡†å·®: {linear_std:.6f}")
print(f"  è§’é€Ÿåº¦æ ‡å‡†å·®: {angular_std:.6f}")

if linear_std < 0.01 and angular_std < 0.05:
    print(f"  âš ï¸  åŠ¨ä½œæ ‡å‡†å·®æå° - å‡ ä¹å®Œå…¨ç›¸åŒçš„è½¨è¿¹")

original_env.close()

# æµ‹è¯•2: åœ¨ä¸åŒç›®æ ‡ç‚¹ä¸Šæµ‹è¯•æ³›åŒ–èƒ½åŠ›
print(f"\n{'='*70}")
print("ã€æµ‹è¯•2ã€‘æ³›åŒ–èƒ½åŠ›æµ‹è¯• - ä¸åŒç›®æ ‡ç‚¹")
print(f"{'='*70}")

test_goals = [
    (1.0, 1.0, "è¿‘è·ç¦»"),
    (2.0, 2.0, "è®­ç»ƒç›®æ ‡"),
    (3.0, 3.0, "ä¸­è·ç¦»"),
    (4.0, 4.0, "è¿œè·ç¦»"),
    (5.0, 5.0, "å¾ˆè¿œ"),
    (2.0, 3.0, "ä¸åŒæ–¹å‘1"),
    (3.0, 2.0, "ä¸åŒæ–¹å‘2"),
    (1.5, 2.5, "ä¸åŒæ–¹å‘3"),
]

results = []

for goal_x, goal_y, desc in test_goals:
    env = ClearpathNavEnv(goal_pos=(goal_x, goal_y))
    
    success_count = 0
    steps_list = []
    
    for _ in range(5):  # æ¯ä¸ªç›®æ ‡æµ‹è¯•5æ¬¡
        obs, _ = env.reset()
        done = False
        step = 0
        
        while not done and step < 256:
            action = agent.select_action(obs)
            obs, reward, done, truncated, info = env.step(action)
            step += 1
            
            if done or truncated:
                break
        
        if info.get('goal_reached'):
            success_count += 1
        steps_list.append(step)
    
    distance = np.sqrt(goal_x**2 + goal_y**2)
    results.append({
        'goal': (goal_x, goal_y),
        'desc': desc,
        'distance': distance,
        'success_rate': success_count / 5,
        'avg_steps': np.mean(steps_list),
        'std_steps': np.std(steps_list)
    })
    
    env.close()
    
    print(f"\nç›®æ ‡ ({goal_x:.1f}, {goal_y:.1f}) - {desc} (è·ç¦»{distance:.2f}m)")
    print(f"  æˆåŠŸç‡: {success_count}/5 ({success_count/5*100:.0f}%)")
    print(f"  å¹³å‡æ­¥æ•°: {np.mean(steps_list):.1f} Â± {np.std(steps_list):.1f}")

# åˆ†æç»“æœ
print(f"\n{'='*70}")
print("è¯Šæ–­ç»“è®º")
print(f"{'='*70}")

training_goal_result = [r for r in results if r['goal'] == (2.0, 2.0)][0]
other_results = [r for r in results if r['goal'] != (2.0, 2.0)]

print(f"\n1. è®­ç»ƒç›®æ ‡(2,2)æ€§èƒ½:")
print(f"   æˆåŠŸç‡: {training_goal_result['success_rate']*100:.0f}%")
print(f"   æ­¥æ•°æ ‡å‡†å·®: {training_goal_result['std_steps']:.2f}")

avg_other_success = np.mean([r['success_rate'] for r in other_results])
print(f"\n2. å…¶ä»–ç›®æ ‡å¹³å‡æ€§èƒ½:")
print(f"   æˆåŠŸç‡: {avg_other_success*100:.0f}%")

print(f"\n3. è¿‡æ‹ŸåˆæŒ‡æ ‡:")

# æŒ‡æ ‡1: è®­ç»ƒç›®æ ‡vså…¶ä»–ç›®æ ‡çš„æˆåŠŸç‡å·®å¼‚
success_gap = training_goal_result['success_rate'] - avg_other_success
print(f"   æˆåŠŸç‡å·®è·: {success_gap*100:.1f}%")

if success_gap > 0.3:
    print(f"   âš ï¸  ä¸¥é‡è¿‡æ‹Ÿåˆ - åœ¨è®­ç»ƒç›®æ ‡ä¸Šè¡¨ç°æ˜æ˜¾æ›´å¥½")
elif success_gap > 0.1:
    print(f"   âš ï¸  è½»åº¦è¿‡æ‹Ÿåˆ")
else:
    print(f"   âœ“ æ³›åŒ–èƒ½åŠ›è‰¯å¥½")

# æŒ‡æ ‡2: æ­¥æ•°ä¸€è‡´æ€§
if training_goal_result['std_steps'] < 3:
    print(f"   âš ï¸  æ­¥æ•°æ ‡å‡†å·®<3 - ç½‘ç»œè®°ä½äº†å›ºå®šç­–ç•¥")
else:
    print(f"   âœ“ æ­¥æ•°æœ‰åˆç†å˜åŒ–")

# æŒ‡æ ‡3: è·ç¦»æ¯”ä¾‹åˆ†æ
print(f"\n4. è·ç¦»-æ­¥æ•°å…³ç³»:")
for r in sorted(results, key=lambda x: x['distance']):
    steps_per_meter = r['avg_steps'] / r['distance'] if r['distance'] > 0 else 0
    print(f"   {r['distance']:.2f}m: {r['avg_steps']:.1f}æ­¥ "
          f"({steps_per_meter:.1f}æ­¥/ç±³) æˆåŠŸç‡{r['success_rate']*100:.0f}%")

# å»ºè®®
print(f"\n{'='*70}")
print("æ”¹è¿›å»ºè®®")
print(f"{'='*70}")

print(f"\nå¦‚æœå‘ç°è¿‡æ‹Ÿåˆï¼Œå»ºè®®:")
print(f"  1. å¢åŠ ä»»åŠ¡éš¾åº¦:")
print(f"     - ç›®æ ‡ç‚¹è®¾ç½®ä¸ºéšæœº: goal_pos=(random.uniform(2,5), random.uniform(2,5))")
print(f"     - å¢åŠ éšœç¢ç‰©")
print(f"     - æ›´å¤æ‚çš„ç¯å¢ƒ")
print(f"")
print(f"  2. å‡å°‘è®­ç»ƒæ—¶é—´:")
print(f"     - 100kæ­¥å¯¹äº2.83mçš„ç®€å•ä»»åŠ¡æ¥è¯´å¤ªå¤šäº†")
print(f"     - å»ºè®®: 30k-50kæ­¥")
print(f"")
print(f"  3. å¢åŠ æ¢ç´¢:")
print(f"     - å¢åŠ åŠ¨ä½œå™ªå£°")
print(f"     - ä½¿ç”¨curriculum learningï¼ˆç”±æ˜“åˆ°éš¾ï¼‰")
print(f"")
print(f"  4. æ•°æ®å¢å¼º:")
print(f"     - åœ¨è®­ç»ƒä¸­æ·»åŠ è§‚æµ‹å™ªå£°")
print(f"     - éšæœºåˆå§‹ä½ç½®å’Œæœå‘")

# å¯è§†åŒ–ï¼ˆå¦‚æœmatplotlibå¯ç”¨ï¼‰
try:
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # å·¦å›¾: è·ç¦» vs æˆåŠŸç‡
    distances = [r['distance'] for r in results]
    success_rates = [r['success_rate']*100 for r in results]
    colors = ['red' if r['goal'] == (2.0, 2.0) else 'blue' for r in results]
    
    axes[0].scatter(distances, success_rates, c=colors, s=100, alpha=0.6)
    axes[0].axhline(y=100, color='green', linestyle='--', alpha=0.3)
    axes[0].set_xlabel('Distance to Goal (m)')
    axes[0].set_ylabel('Success Rate (%)')
    axes[0].set_title('Generalization Test')
    axes[0].grid(True, alpha=0.3)
    axes[0].legend(['Training goal (2,2)', 'Other goals'], loc='lower left')
    
    # å³å›¾: è·ç¦» vs å¹³å‡æ­¥æ•°
    avg_steps = [r['avg_steps'] for r in results]
    axes[1].scatter(distances, avg_steps, c=colors, s=100, alpha=0.6)
    axes[1].set_xlabel('Distance to Goal (m)')
    axes[1].set_ylabel('Average Steps')
    axes[1].set_title('Steps vs Distance')
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('overfitting_analysis.png', dpi=150)
    print(f"\nğŸ“Š å¯è§†åŒ–å·²ä¿å­˜åˆ°: overfitting_analysis.png")
except Exception as e:
    print(f"\n(å¯è§†åŒ–è·³è¿‡: {e})")

print(f"\n{'='*70}")